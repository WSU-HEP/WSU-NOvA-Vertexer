{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDE & ML Based NuMu Event Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Classes & Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Ensure all required python classes are installed prior to progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import warnings\n",
    "import struct\n",
    "import binascii\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from IPython.display import display, clear_output\n",
    "from matplotlib.image import imread # read images\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.signal import find_peaks\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten,Activation,concatenate\n",
    "from tensorflow.keras.optimizers import Adam #optimizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.preprocessing import MinMaxScaler # normalize and scale data\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score,r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory paths for train & test data sets\n",
    "data_dir='/home/m962g264/research_repo/data-preprocess'\n",
    "train_path=data_dir+'/MC_Nominal_FHC_train_abdul/'\n",
    "test_path=data_dir+'/MC_Nominal_FHC_testdata_abdul/'\n",
    "print('Training files path: \\t{}'.format(train_path))\n",
    "print('Validation files path: \\t{}'.format(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = list(set(n for n in os.listdir(train_path) if n.endswith(\".h5\")))\n",
    "test_files = list(set(n for n in os.listdir(test_path) if n.endswith(\".h5\")))\n",
    "# train & test size\n",
    "train_idx=0\n",
    "test_idx=0\n",
    "for h5_filename in os.listdir(train_path):\n",
    "    #Adding these two lines to avoid errors because there are extra directories in the FHC set for some reason\n",
    "    if os.path.isdir(h5_filename)==True:\n",
    "        continue\n",
    "    \n",
    "    train_idx=train_idx+len((h5py.File(train_path+h5_filename,'r')['run'][:]))\n",
    "for h5_filename in os.listdir(test_path):\n",
    "    test_idx=test_idx+len((h5py.File(test_path+h5_filename,'r')['run'][:]))\n",
    "\n",
    "# training events are broad scoped while validation events are quality cut ND contained. further train/test splitting is done later.\n",
    "print('Number of training files:\\t{}\\nNumber of validation files:\\t{}'.format(len(os.listdir(train_path)), len(os.listdir(test_path))))\n",
    "print('Number of training events:\\t{}\\nNumber of validation events:\\t{}'.format((train_idx), (test_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test interaction is canoncial for training files\n",
    "df=h5py.File(train_path+os.listdir(train_path)[0],'r')\n",
    "print(list(df.keys()))\n",
    "\n",
    "f=h5py.File(test_path+os.listdir(test_path)[0],'r')\n",
    "print(list(f.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all the h5 files\n",
    "idx=0\n",
    "energy,pdg,cvnmap,test_cvnmap,truerecovtxx,truerecovtxy,truerecovtxz,test_mode,test_iscc,testtruerecovtxx,testtruerecovtxy,testtruerecovtxz=([] for i in range(12))\n",
    "for h5_filename in os.listdir(train_path):\n",
    "        #Adding these two lines to avoid errors because there are extra directories in the FHC set for some reason\n",
    "    if os.path.isdir(h5_filename)==True:\n",
    "        continue\n",
    "    print('Processing... {} of {}'.format(idx,len(os.listdir(train_path))), end=\"\\r\", flush=True)\n",
    "    energy=np.append(energy, h5py.File(train_path+h5_filename,'r')['E'][:],axis=0)\n",
    "    pdg=np.append(pdg,h5py.File(train_path+h5_filename,'r')['PDG'][:],axis=0)\n",
    "    cvnmap.append(h5py.File(train_path+h5_filename,'r')['cvnmap'][:])\n",
    "    truerecovtxz.append(h5py.File(train_path+h5_filename,'r')['TrueRecoVtxZ'][:])\n",
    "    test_cvnmap.append(h5py.File(test_path+h5_filename,'r')['cvnmap'][:])\n",
    "    train_mode=np.append(test_mode,h5py.File(train_path+h5_filename,'r')['Mode'][:],axis=0)\n",
    "    train_iscc=np.append(test_iscc,h5py.File(train_path+h5_filename,'r')['isCC'][:],axis=0)\n",
    "    test_mode=np.append(test_mode,h5py.File(test_path+h5_filename,'r')['Mode'][:],axis=0)\n",
    "    test_iscc=np.append(test_iscc,h5py.File(test_path+h5_filename,'r')['isCC'][:],axis=0)\n",
    "    testtruerecovtxz.append(h5py.File(test_path+h5_filename,'r')['TrueRecoVtxZ'][:])\n",
    "    idx+=1\n",
    "\n",
    "# convert to np array\n",
    "truerecovtxz=np.array(truerecovtxz)\n",
    "testtruerecovtxz=np.array(testtruerecovtxz)\n",
    "print('Test & Validation files read successful') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize cvnmap for CNN processing\n",
    "# training data\n",
    "idx=file=0\n",
    "cvnmap_norm,test_cvnmap_norm=([] for i in range(2))\n",
    "while idx < (len(os.listdir(train_path))):\n",
    "        #seeing if we can fix the index problem\n",
    "    #if idx==2001:\n",
    "        #break\n",
    "    \n",
    "    cvnmap_norm.append(preprocessing.normalize(cvnmap[idx],axis=1))\n",
    "    idx+=1\n",
    "# testing data\n",
    "while file < (len(os.listdir(test_path))):\n",
    "    test_cvnmap_norm.append(preprocessing.normalize(test_cvnmap[file],axis=1))\n",
    "    file+=1\n",
    "# convert to np array\n",
    "cvnmap_norm=np.array(cvnmap_norm)\n",
    "test_cvnmap_norm=np.array(test_cvnmap_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract true vertices for model training processing and model validation\n",
    "truevtxz,recovtxz,testtruevtxz,testrecovtxz=([] for i in range(4))\n",
    "idx=0\n",
    "while idx < (len(os.listdir(train_path))):\n",
    "        print('Processing...', end=\"\\r\", flush=True)\n",
    "        event=0\n",
    "        #seeing if we can fix the index problem\n",
    "        \n",
    "        #if idx==2001:\n",
    "            #break\n",
    "        \n",
    "        while event < (truerecovtxz[idx].shape[0]):\n",
    "            truevtxz=np.append(truevtxz,truerecovtxz[idx][event][0])\n",
    "            recovtxz=np.append(recovtxz,truerecovtxz[idx][event][1])\n",
    "            event+=1\n",
    "        idx+=1\n",
    "print('Training preprocessing complete\\n', end=\"\\r\", flush=True)\n",
    "idx=0\n",
    "while idx < (len(os.listdir(test_path))):\n",
    "        print('Processing...', end=\"\\r\", flush=True)\n",
    "        event=0\n",
    "        while event < (testtruerecovtxz[idx].shape[0]):\n",
    "            testtruevtxz=np.append(testtruevtxz,testtruerecovtxz[idx][event][0])\n",
    "            testrecovtxz=np.append(testrecovtxz,testtruerecovtxz[idx][event][1])\n",
    "            event+=1\n",
    "        idx+=1\n",
    "print('Testing preprocessing complete\\n', end=\"\\r\", flush=True)\n",
    "# convert to np arrays\n",
    "testtruevtxz=np.array(testtruevtxz)\n",
    "testrecovtxz=np.array(testrecovtxz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split normalized cvnmap into reshaped events with multi-views\n",
    "a,b,c,d,cvnmap_norm_resh,cvnmap_norm_resh_xz,cvnmap_norm_resh_yz,test_cvnmap_norm_resh,test_cvnmap_norm_resh_xz,test_cvnmap_norm_resh_yz=([] for i in range(10))\n",
    "file=event=0\n",
    "## training CVN map view split ##\n",
    "while file < (len(os.listdir(train_path))):\n",
    "        #seeing if we can fix the index problem\n",
    "    #if idx==2001:\n",
    "        #break\n",
    "    \n",
    "    a=cvnmap_norm[file]\n",
    "    print('Processing train cvnmap file {} of {}'.format(file+1, (len(os.listdir(train_path)))), end=\"\\r\", flush=True)\n",
    "    event=0\n",
    "    while event < (a.shape[0]):\n",
    "        b=a[event].reshape(2,100,80)\n",
    "        cvnmap_norm_resh.append(b)\n",
    "        cvnmap_norm_resh_xz.append(b[0])\n",
    "        cvnmap_norm_resh_yz.append(b[1])\n",
    "        event+=1\n",
    "    file+=1\n",
    "file=event=0\n",
    "while file < (len(os.listdir(test_path))):\n",
    "    c=test_cvnmap_norm[file]\n",
    "    print('Processing tests cvnmap file {} of {}'.format(file+1, (len(os.listdir(test_path)))), end=\"\\r\", flush=True)\n",
    "    event=0\n",
    "    while event < (c.shape[0]):\n",
    "        d=c[event].reshape(2,100,80)\n",
    "        test_cvnmap_norm_resh.append(d)\n",
    "        test_cvnmap_norm_resh_xz.append(d[0])\n",
    "        test_cvnmap_norm_resh_yz.append(d[1])\n",
    "        event+=1\n",
    "    file+=1\n",
    "print('\\ncvnmap processing complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defines the finalstate array! Need to make a numpy array from the extracted final state pdg information\n",
    "pdgpath='/home/m964g264/ondemand/research_repo/data-preprocess/ND_MC_Nominal_Files_FHC_mominkhan/'\n",
    "idx=0\n",
    "for h5_filename in os.listdir(pdgpath):\n",
    "        #Adding these two lines to avoid errors because there are extra directories in the FHC set for some reason\n",
    "    if os.path.isdir(h5_filename)==True:\n",
    "        continue\n",
    "        \n",
    "    print('Processing... {} of {}'.format(idx,len(os.listdir(train_path))), end=\"\\r\", flush=True)\n",
    "   \n",
    "    g=h5py.File(pdgpath+h5_filename,'r')\n",
    "    finalstate=g['rec.mc.nu.prim']['pdg'][:]\n",
    " \n",
    "    idx+=1\n",
    "    \n",
    "# convert to np array\n",
    "print('Test & Validation files read successful') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split Datasets by Interaction Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cvnmap_qe_xz,test_cvnmap_qe_yz,test_cvnmap_res_xz,test_cvnmap_res_yz,test_cvnmap_dis_xz,test_cvnmap_dis_yz=([] for i in range(6))\n",
    "qe_true_vtxz,res_true_vtxz,dis_true_vtxz,qe_reco_vtxz,res_reco_vtxz,dis_reco_vtxz=([] for i in range(6))\n",
    "x=idx=0\n",
    "print('Processing {} test files. Splitting events by interaction mode.'.format((len(test_mode))))\n",
    "#############MODE####################################################\n",
    "while idx < (len(test_mode)):\n",
    "    time.sleep(0.001) # hesitates for 0.001 seconds to prevent server comm errors\n",
    "    print('MODE RUN: Processing train file {}'.format(idx), end=\"\\r\", flush=True)\n",
    "    if test_mode[idx] == 0.0: # quasi-elastic\n",
    "        test_cvnmap_qe_xz.append(test_cvnmap_norm_resh_xz[idx])\n",
    "        test_cvnmap_qe_yz.append(test_cvnmap_norm_resh_yz[idx])\n",
    "        qe_true_vtxz.append(testtruevtxz[idx])\n",
    "        qe_reco_vtxz.append(testrecovtxz[idx])\n",
    "    elif test_mode[idx] == 1.0: # resonance state\n",
    "        test_cvnmap_res_xz.append(test_cvnmap_norm_resh_xz[idx])\n",
    "        test_cvnmap_res_yz.append(test_cvnmap_norm_resh_yz[idx])\n",
    "        res_true_vtxz.append(testtruevtxz[idx])\n",
    "        res_reco_vtxz.append(testrecovtxz[idx])\n",
    "    elif test_mode[idx] == 2.0: # deep inelastic\n",
    "        test_cvnmap_dis_xz.append(test_cvnmap_norm_resh_xz[idx])\n",
    "        test_cvnmap_dis_yz.append(test_cvnmap_norm_resh_yz[idx])\n",
    "        dis_true_vtxz.append(testtruevtxz[idx])\n",
    "        dis_reco_vtxz.append(testrecovtxz[idx])\n",
    "    idx+=1\n",
    "print('\\nJob complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############CC/NC###################################################\n",
    "test_cvnmap_cc_xz,test_cvnmap_cc_yz,test_cvnmap_nc_xz,test_cvnmap_nc_yz=([] for i in range(4))\n",
    "cc_true_vtxz,nc_true_vtxz,cc_reco_vtxz,nc_reco_vtxz=([] for i in range(4))\n",
    "x=idx=0\n",
    "print('Processing {} test files. Splitting events by interactions current charge.'.format((len(test_mode))))\n",
    "while idx < (len(test_mode)):\n",
    "    time.sleep(0.001) # hesitates for 0.001 seconds to prevent server comm errors\n",
    "    print('CC/NC RUN: Processing train file {}'.format(idx), end=\"\\r\", flush=True)\n",
    "    if test_iscc[idx] == 1.0: # cc\n",
    "        test_cvnmap_cc_xz.append(test_cvnmap_norm_resh_xz[idx])\n",
    "        test_cvnmap_cc_yz.append(test_cvnmap_norm_resh_yz[idx])\n",
    "        cc_true_vtxz.append(testtruevtxz[idx])\n",
    "        cc_reco_vtxz.append(testrecovtxz[idx])\n",
    "    elif test_iscc[idx] == 0.0: # nc\n",
    "        test_cvnmap_nc_xz.append(test_cvnmap_norm_resh_xz[idx])\n",
    "        test_cvnmap_nc_yz.append(test_cvnmap_norm_resh_yz[idx])\n",
    "        nc_true_vtxz.append(testtruevtxz[idx])\n",
    "        nc_reco_vtxz.append(testrecovtxz[idx])\n",
    "    idx+=1\n",
    "print('\\nJob complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract reco data sets from training\n",
    "qe_reco_vtxz,res_reco_vtxz,dis_reco_vtxz=([] for i in range(3))\n",
    "qe_reco_true_vtxz,res_reco_true_vtxz,dis_reco_true_vtxz=([] for i in range(3))\n",
    "x=idx=0\n",
    "print('Processing {} train files. Splitting events by interaction mode.'.format((len(train_mode))))\n",
    "#############MODE####################################################\n",
    "while idx < (len(train_mode)):\n",
    "    time.sleep(0.001) # hesitates for 0.001 seconds to prevent server comm errors\n",
    "    print('MODE RUN: Processing train file {}'.format(idx), end=\"\\r\", flush=True)\n",
    "    if train_mode[idx] == 0.0: # quasi-elastic\n",
    "        qe_reco_vtxz.append(recovtxz[idx])\n",
    "        qe_reco_true_vtxz.append(truevtxz[idx])\n",
    "    elif train_mode[idx] == 1.0: # resonance state\n",
    "        res_reco_vtxz.append(recovtxz[idx])\n",
    "        res_reco_true_vtxz.append(truevtxz[idx])\n",
    "    elif train_mode[idx] == 2.0: # deep inelastic\n",
    "        dis_reco_vtxz.append(recovtxz[idx])\n",
    "        dis_reco_true_vtxz.append(truevtxz[idx])\n",
    "    idx+=1\n",
    "print('\\nJob complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############CC/NC###################################################\n",
    "cc_reco_vtxz,nc_reco_vtxz,cc_reco_true_vtxz,nc_reco_true_vtxz=([] for i in range(4))\n",
    "x=idx=0\n",
    "print('Processing {} test files. Splitting events by interactions current charge.'.format((len(train_mode))))\n",
    "while idx < (len(train_mode)):\n",
    "    time.sleep(0.001) # hesitates for 0.001 seconds to prevent server comm errors\n",
    "    print('CC/NC RUN: Processing train file {}'.format(idx), end=\"\\r\", flush=True)\n",
    "    if train_iscc[idx] == 1.0: # cc\n",
    "        cc_reco_vtxz.append(recovtxz[idx])\n",
    "        cc_reco_true_vtxz.append(truevtxz[idx])\n",
    "    elif train_iscc[idx] == 0.0: # nc\n",
    "        nc_reco_vtxz.append(recovtxz[idx])\n",
    "        nc_reco_true_vtxz.append(truevtxz[idx])\n",
    "    idx+=1\n",
    "print('\\nJob complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Split by pdg number for pions #######\n",
    "finalstatepizero,finalstatepiplus,pizerorecovtxz,pizerotruevtxz,pizerotestrecovtxz,pizerotesttruevtxz,piplusrecovtxz,piplustruevtxz,piplustestrecovtxz,piplustesttruevtxz=([] for i in range(10))\n",
    "x=idx=0\n",
    "print('Processing {} test files. Splitting events by final state pdg code.'.format((len(finalstate))))\n",
    "while idx < (len(finalstate)):\n",
    "    time.sleep(0.001) # hesitates for 0.001 seconds to prevent server comm errors\n",
    "    print('PI 0 RUN: Processing train file {}'.format(idx), end=\"\\r\", flush=True)\n",
    "    if finalstate[idx] == 111: # pdg code for Pi 0 particle\n",
    "        \n",
    "        pizerorecovtxz.append(recovtxz[idx])\n",
    "        pizerotruevtxz.append(truevtxz[idx])\n",
    "    \n",
    "        \n",
    "        pizerotestrecovtxz.append(testrecovtxz[idx])\n",
    "        pizerotesttruevtxz.append(testtruevtxz[idx])\n",
    "    \n",
    "        \n",
    "        \n",
    "    elif finalstate[idx] == 211: #pd code for a pi +\n",
    "        finalstatepiplus.append(finalstate[idx])\n",
    "        \n",
    "        piplusrecovtxz.append(recovtxz[idx])\n",
    "        piplustruevtxz.append(truevtxz[idx])\n",
    "        \n",
    "        piplustestrecovtxz.append(testrecovtxz[idx])\n",
    "        piplustesttruevtxz.append(testtruevtxz[idx])\n",
    "       \n",
    "\n",
    "    idx+=1\n",
    "print('\\nJob complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determining spread for pi0 old algorithm\n",
    "pizerorecovtxz=np.array(pizerorecovtxz)\n",
    "pizerotruevtxz=np.array(pizerotruevtxz)\n",
    "diff_reco_pi_zero=pizerorecovtxz-pizerotruevtxz\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.displot(diff_reco_pi_zero,color='k')\n",
    "plt.ylim(0, 1000)\n",
    "plt.xlim(-300, 300)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "#calculating mean and stuff\n",
    "averagex=np.mean(diff_reco_pi_zero)\n",
    "print(\"The mean is\" , averagex)\n",
    "\n",
    "#Calculating RMS\n",
    "rmsx=np.sqrt(np.mean(diff_reco_pi_zero**2))\n",
    "print(\"The RMS is \" , rmsx)\n",
    "#areaofinterestx=3*rmsx-averagex\n",
    "#print(\"The range of 3 sigma we are counting inside of is \", areaofinterestx)\n",
    "areaofinterestx=200\n",
    "\n",
    "#total number of events\n",
    "totalevents=len(diff_reco_pi_zero)\n",
    "print(\"The total number of events is \" , totalevents)\n",
    "#Counting events within 3 sigma\n",
    "y=0\n",
    "for x in diff_reco_pi_zero:\n",
    "    if x < abs(areaofinterestx):\n",
    "        y=y+1\n",
    "    else:\n",
    "        continue\n",
    "percentcount=y/totalevents\n",
    "print(\"The number events within plus minus 200 is \", y,\"This is\", 100*percentcount, \"% of all events\")\n",
    "print(\"The number of events outside this range is\", totalevents-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data = np.random.normal(loc=5.0, scale=2.0, size=1000)\n",
    "mean,std=norm.fit(diff_reco_pi_zero)\n",
    "\n",
    "plt.hist(diff_reco_pi_zero, bins=1000, normed=True)\n",
    "xmin, xmax = plt.xlim(-200,200)\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "y = norm.pdf(x, mean, std)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "#gauss_fit,cov = curve_fit( Gauss, x, y )\n",
    "print(\"gaussian fit params: The Mean is \", mean)\n",
    "print(\"The STD is \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model results for pi zero\n",
    "pizerotestrecovtxz=np.array(pizerotestrecovtxz)\n",
    "pizerotesttruevtxz=np.array(pizerotesttruevtxz)\n",
    "diff_reco_pi_zero_test=pizerotestrecovtxz-pizerotesttruevtxz\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.displot(diff_reco_pi_zero_test,color='k')\n",
    "plt.ylim(0, 1000)\n",
    "plt.xlim(-300, 300)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "#calculating mean and stuff\n",
    "averagex=np.mean(diff_reco_pi_zero_test)\n",
    "print(\"The mean is\" , averagex)\n",
    "\n",
    "#Calculating RMS\n",
    "rmsx=np.sqrt(np.mean(diff_reco_pi_zero_test**2))\n",
    "print(\"The RMS is \" , rmsx)\n",
    "#areaofinterestx=3*rmsx-averagex\n",
    "#print(\"The range of 3 sigma we are counting inside of is \", areaofinterestx)\n",
    "areaofinterestx=200\n",
    "\n",
    "#total number of events\n",
    "totalevents=len(diff_reco_pi_zero_test)\n",
    "print(\"The total number of events is \" , totalevents)\n",
    "#Counting events within 3 sigma\n",
    "y=0\n",
    "for x in diff_reco_pi_zero_test:\n",
    "    if x < abs(areaofinterestx):\n",
    "        y=y+1\n",
    "    else:\n",
    "        continue\n",
    "percentcount=y/totalevents\n",
    "print(\"The number events within plus minus 200 is \", y,\"This is\", 100*percentcount, \"% of all events\")\n",
    "print(\"The number of events outside this range is\", totalevents-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data = np.random.normal(loc=5.0, scale=2.0, size=1000)\n",
    "mean,std=norm.fit(diff_reco_pi_zero_test)\n",
    "\n",
    "plt.hist(diff_reco_pi_zero_test, bins=1000, normed=True)\n",
    "xmin, xmax = plt.xlim(-200,200)\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "y = norm.pdf(x, mean, std)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "#gauss_fit,cov = curve_fit( Gauss, x, y )\n",
    "print(\"gaussian fit params: The Mean is \", mean)\n",
    "print(\"The STD is \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determining spread for pi plus old algorithm\n",
    "piplusrecovtxz=np.array(piplusrecovtxz)\n",
    "piplustruevtxz=np.array(piplustruevtxz)\n",
    "diff_reco_pi_plus=piplusrecovtxz-piplustruevtxz\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.displot(diff_reco_pi_plus,color='k')\n",
    "plt.ylim(0, 1000)\n",
    "plt.xlim(-300, 300)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "#calculating mean and stuff\n",
    "averagex=np.mean(diff_reco_pi_plus)\n",
    "print(\"The mean is\" , averagex)\n",
    "\n",
    "#Calculating RMS\n",
    "rmsx=np.sqrt(np.mean(diff_reco_pi_plus**2))\n",
    "print(\"The RMS is \" , rmsx)\n",
    "#areaofinterestx=3*rmsx-averagex\n",
    "#print(\"The range of 3 sigma we are counting inside of is \", areaofinterestx)\n",
    "areaofinterestx=200\n",
    "\n",
    "#total number of events\n",
    "totalevents=len(diff_reco_pi_plus)\n",
    "print(\"The total number of events is \" , totalevents)\n",
    "#Counting events within 3 sigma\n",
    "y=0\n",
    "for x in diff_reco_pi_plus:\n",
    "    if x < abs(areaofinterestx):\n",
    "        y=y+1\n",
    "    else:\n",
    "        continue\n",
    "percentcount=y/totalevents\n",
    "print(\"The number events within plus minus 200 is \", y,\"This is\", 100*percentcount, \"% of all events\")\n",
    "print(\"The number of events outside this range is\", totalevents-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data = np.random.normal(loc=5.0, scale=2.0, size=1000)\n",
    "mean,std=norm.fit(diff_reco_pi_plus)\n",
    "\n",
    "plt.hist(diff_reco_pi_plus, bins=10000, normed=True)\n",
    "xmin, xmax = plt.xlim(-200,200)\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "y = norm.pdf(x, mean, std)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "#gauss_fit,cov = curve_fit( Gauss, x, y )\n",
    "print(\"gaussian fit params: The Mean is \", mean)\n",
    "print(\"The STD is \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model results for pi plus\n",
    "piplustestrecovtxz=np.array(piplustestrecovtxz)\n",
    "piplustesttruevtxz=np.array(piplustesttruevtxz)\n",
    "diff_reco_pi_plus_test=piplustestrecovtxz-piplustesttruevtxz\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.displot(diff_reco_pi_plus_test,color='k')\n",
    "plt.ylim(0, 300)\n",
    "plt.xlim(-300, 300)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "#calculating mean and stuff\n",
    "averagex=np.mean(diff_reco_pi_plus_test)\n",
    "print(\"The mean is\" , averagex)\n",
    "\n",
    "#Calculating RMS\n",
    "rmsx=np.sqrt(np.mean(diff_reco_pi_plus_test**2))\n",
    "print(\"The RMS is \" , rmsx)\n",
    "#areaofinterestx=3*rmsx-averagex\n",
    "#print(\"The range of 3 sigma we are counting inside of is \", areaofinterestx)\n",
    "areaofinterestx=200\n",
    "\n",
    "#total number of events\n",
    "totalevents=len(diff_reco_pi_plus_test)\n",
    "print(\"The total number of events is \" , totalevents)\n",
    "#Counting events within 3 sigma\n",
    "y=0\n",
    "for x in diff_reco_pi_plus_test:\n",
    "    if x < abs(areaofinterestx):\n",
    "        y=y+1\n",
    "    else:\n",
    "        continue\n",
    "percentcount=y/totalevents\n",
    "print(\"The number events within plus minus 200 is \", y,\"This is\", 100*percentcount, \"% of all events\")\n",
    "print(\"The number of events outside this range is\", totalevents-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data = np.random.normal(loc=5.0, scale=2.0, size=1000)\n",
    "mean,std=norm.fit(diff_reco_pi_plus_test)\n",
    "\n",
    "plt.hist(diff_reco_pi_plus_test, bins=1000, normed=True)\n",
    "xmin, xmax = plt.xlim(-200,200)\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "y = norm.pdf(x, mean, std)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "#gauss_fit,cov = curve_fit( Gauss, x, y )\n",
    "print(\"gaussian fit params: The Mean is \", mean)\n",
    "print(\"The STD is \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Split by pdg number for muon #######\n",
    "finalstatemuon,finalstateantimuon,muonrecovtxz,muontruevtxz,muontestrecovtxz,muontesttruevtxz,antimuonrecovtxz,antimuontruevtxz,antimuontestrecovtxz,antimuontesttruevtxz=([] for i in range(10))\n",
    "x=idx=0\n",
    "print('Processing {} test files. Splitting events by final state pdg code.'.format((len(pdg))))\n",
    "while idx < (len(finalstate)):\n",
    "    time.sleep(0.001) # hesitates for 0.001 seconds to prevent server comm errors\n",
    "    print('MUON RUN: Processing train file {}'.format(idx), end=\"\\r\", flush=True)\n",
    "    if finalstate[idx] == 13: # pdg code for normal muon particle\n",
    "       \n",
    "        \n",
    "        finalstatemuon.append(finalstate[idx])\n",
    "        \n",
    "        muonrecovtxz.append(recovtxz[idx])\n",
    "        muontruevtxz.append(truevtxz[idx])\n",
    "        \n",
    "        muontestrecovtxz.append(testrecovtxz[idx])\n",
    "        muontesttruevtxz.append(testtruevtxz[idx])\n",
    "        \n",
    "        \n",
    "    elif finalstate[idx] == -13: #pd code for an anti muon\n",
    "        finalstateantimuon.append(finalstate[idx])\n",
    "        \n",
    "        antimuonrecovtxz.append(recovtxz[idx])\n",
    "        antimuontruevtxz.append(truevtxz[idx])\n",
    "        \n",
    "        antimuontestrecovtxz.append(testrecovtxz[idx])\n",
    "        antimuontesttruevtxz.append(testtruevtxz[idx])\n",
    "       \n",
    "\n",
    "    idx+=1\n",
    "print('\\nJob complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determining spread for muon old algorithm\n",
    "muonrecovtxz=np.array(muonrecovtxz)\n",
    "muontruevtxz=np.array(muontruevtxz)\n",
    "diff_reco_muon=muonrecovtxz-muontruevtxz\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.displot(diff_reco_muon,color='k')\n",
    "plt.ylim(0, 300)\n",
    "plt.xlim(-300, 300)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "#calculating mean and stuff\n",
    "averagex=np.mean(diff_reco_muon)\n",
    "print(\"The mean is\" , averagex)\n",
    "\n",
    "#Calculating RMS\n",
    "rmsx=np.sqrt(np.mean(diff_reco_muon**2))\n",
    "print(\"The RMS is \" , rmsx)\n",
    "#areaofinterestx=3*rmsx-averagex\n",
    "#print(\"The range of 3 sigma we are counting inside of is \", areaofinterestx)\n",
    "areaofinterestx=200\n",
    "\n",
    "#total number of events\n",
    "totalevents=len(diff_reco_muon)\n",
    "print(\"The total number of events is \" , totalevents)\n",
    "#Counting events within 3 sigma\n",
    "y=0\n",
    "for x in diff_reco_muon:\n",
    "    if x < abs(areaofinterestx):\n",
    "        y=y+1\n",
    "    else:\n",
    "        continue\n",
    "percentcount=y/totalevents\n",
    "print(\"The number events within plus minus 200 is \", y,\"This is\", 100*percentcount, \"% of all events\")\n",
    "print(\"The number of events outside this range is\", totalevents-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data = np.random.normal(loc=5.0, scale=2.0, size=1000)\n",
    "mean,std=norm.fit(diff_reco_muon)\n",
    "\n",
    "plt.hist(diff_reco_muon, bins=5000, normed=True)\n",
    "xmin, xmax = plt.xlim(-200,200)\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "y = norm.pdf(x, mean, std)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "#gauss_fit,cov = curve_fit( Gauss, x, y )\n",
    "print(\"gaussian fit params: The Mean is \", mean)\n",
    "print(\"The STD is \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model results for muon in final state\n",
    "muontestrecovtxz=np.array(muontestrecovtxz)\n",
    "muontesttruevtxz=np.array(muontesttruevtxz)\n",
    "diff_reco_muon_test=muontestrecovtxz-muontesttruevtxz\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.displot(diff_reco_muon_test,color='k')\n",
    "plt.ylim(0, 300)\n",
    "plt.xlim(-300, 300)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "#calculating mean and stuff\n",
    "averagex=np.mean(diff_reco_muon_test)\n",
    "print(\"The mean is\" , averagex)\n",
    "\n",
    "#Calculating RMS\n",
    "rmsx=np.sqrt(np.mean(diff_reco_muon_test**2))\n",
    "print(\"The RMS is \" , rmsx)\n",
    "#areaofinterestx=3*rmsx-averagex\n",
    "#print(\"The range of 3 sigma we are counting inside of is \", areaofinterestx)\n",
    "areaofinterestx=200\n",
    "\n",
    "#total number of events\n",
    "totalevents=len(diff_reco_muon_test)\n",
    "print(\"The total number of events is \" , totalevents)\n",
    "#Counting events within 3 sigma\n",
    "y=0\n",
    "for x in diff_reco_muon_test:\n",
    "    if x < abs(areaofinterestx):\n",
    "        y=y+1\n",
    "    else:\n",
    "        continue\n",
    "percentcount=y/totalevents\n",
    "print(\"The number events within plus minus 200 is \", y,\"This is\", 100*percentcount, \"% of all events\")\n",
    "print(\"The number of events outside this range is\", totalevents-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data = np.random.normal(loc=5.0, scale=2.0, size=1000)\n",
    "mean,std=norm.fit(diff_reco_muon_test)\n",
    "\n",
    "plt.hist(diff_reco_muon_test, bins=1000, normed=True)\n",
    "xmin, xmax = plt.xlim(-200,200)\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "y = norm.pdf(x, mean, std)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "#gauss_fit,cov = curve_fit( Gauss, x, y )\n",
    "print(\"gaussian fit params: The Mean is \", mean)\n",
    "print(\"The STD is \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determining spread for anti muon old algorithm\n",
    "antimuonrecovtxz=np.array(antimuonrecovtxz)\n",
    "antimuontruevtxz=np.array(antimuontruevtxz)\n",
    "diff_reco_anti_muon=antimuonrecovtxz-antimuontruevtxz\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.displot(diff_reco_anti_muon,color='k')\n",
    "plt.ylim(0, 1000)\n",
    "plt.xlim(-300, 300)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "#calculating mean and stuff\n",
    "averagex=np.mean(diff_reco_anti_muon)\n",
    "print(\"The mean is\" , averagex)\n",
    "\n",
    "#Calculating RMS\n",
    "rmsx=np.sqrt(np.mean(diff_reco_anti_muon**2))\n",
    "print(\"The RMS is \" , rmsx)\n",
    "#areaofinterestx=3*rmsx-averagex\n",
    "#print(\"The range of 3 sigma we are counting inside of is \", areaofinterestx)\n",
    "areaofinterestx=200\n",
    "\n",
    "#total number of events\n",
    "totalevents=len(diff_reco_anti_muon)\n",
    "print(\"The total number of events is \" , totalevents)\n",
    "#Counting events within 3 sigma\n",
    "y=0\n",
    "for x in diff_reco_anti_muon:\n",
    "    if x < abs(areaofinterestx):\n",
    "        y=y+1\n",
    "    else:\n",
    "        continue\n",
    "percentcount=y/totalevents\n",
    "print(\"The number events within plus minus 200 is \", y,\"This is\", 100*percentcount, \"% of all events\")\n",
    "print(\"The number of events outside this range is\", totalevents-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data = np.random.normal(loc=5.0, scale=2.0, size=1000)\n",
    "mean,std=norm.fit(diff_reco_anti_muon)\n",
    "\n",
    "plt.hist(diff_reco_anti_muon, bins=5000, normed=True)\n",
    "xmin, xmax = plt.xlim(-200,200)\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "y = norm.pdf(x, mean, std)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "#gauss_fit,cov = curve_fit( Gauss, x, y )\n",
    "print(\"gaussian fit params: The Mean is \", mean)\n",
    "print(\"The STD is \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model results for anti muon in final state\n",
    "antimuontestrecovtxz=np.array(antimuontestrecovtxz)\n",
    "antimuontesttruevtxz=np.array(antimuontesttruevtxz)\n",
    "diff_reco_anti_muon_test=antimuontestrecovtxz-antimuontesttruevtxz\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.displot(diff_reco_anti_muon_test,color='k')\n",
    "plt.ylim(0, 300)\n",
    "plt.xlim(-200, 200)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "#calculating mean and stuff\n",
    "averagex=np.mean(diff_reco_anti_muon_test)\n",
    "print(\"The mean is\" , averagex)\n",
    "\n",
    "#Calculating RMS\n",
    "rmsx=np.sqrt(np.mean(diff_reco_anti_muon_test**2))\n",
    "print(\"The RMS is \" , rmsx)\n",
    "#areaofinterestx=3*rmsx-averagex\n",
    "#print(\"The range of 3 sigma we are counting inside of is \", areaofinterestx)\n",
    "areaofinterestx=200\n",
    "\n",
    "#total number of events\n",
    "totalevents=len(diff_reco_anti_muon_test)\n",
    "print(\"The total number of events is \" , totalevents)\n",
    "#Counting events within 3 sigma\n",
    "y=0\n",
    "for x in diff_reco_anti_muon_test:\n",
    "    if x < abs(areaofinterestx):\n",
    "        y=y+1\n",
    "    else:\n",
    "        continue\n",
    "percentcount=y/totalevents\n",
    "print(\"The number events within plus minus 200 is \", y,\"This is\", 100*percentcount, \"% of all events\")\n",
    "print(\"The number of events outside this range is\", totalevents-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data = np.random.normal(loc=5.0, scale=2.0, size=1000)\n",
    "mean,std=norm.fit(diff_reco_anti_muon_test)\n",
    "\n",
    "plt.hist(diff_reco_anti_muon_test, bins=1000, normed=True)\n",
    "xmin, xmax = plt.xlim(-200,200)\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "y = norm.pdf(x, mean, std)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "#gauss_fit,cov = curve_fit( Gauss, x, y )\n",
    "print(\"gaussian fit params: The Mean is \", mean)\n",
    "print(\"The STD is \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Split by pdg number for electron #######\n",
    "finalstateelectron,finalstatepositron,electronrecovtxz,electrontruevtxz,electrontestrecovtxz,electrontesttruevtxz,positronrecovtxz,positrontruevtxz,positrontestrecovtxz,positrontesttruevtxz=([] for i in range(10))\n",
    "x=idx=0\n",
    "print('Processing {} test files. Splitting events by final state pdg code.'.format((len(pdg))))\n",
    "while idx < (len(finalstate)):\n",
    "    time.sleep(0.001) # hesitates for 0.001 seconds to prevent server comm errors\n",
    "    print('ELECTRON RUN: Processing train file {}'.format(idx), end=\"\\r\", flush=True)\n",
    "    if finalstate[idx] == 11: # pdg code for electron\n",
    "       \n",
    "        \n",
    "        finalstateelectron.append(finalstate[idx])\n",
    "        \n",
    "        electronrecovtxz.append(recovtxz[idx])\n",
    "        electrontruevtxz.append(truevtxz[idx])\n",
    "        \n",
    "        electrontestrecovtxz.append(testrecovtxz[idx])\n",
    "        electrontesttruevtxz.append(testtruevtxz[idx])\n",
    "        \n",
    "        \n",
    "    elif finalstate[idx] == -11: #pd code for an anti muon\n",
    "        finalstatepositron.append(finalstate[idx])\n",
    "        \n",
    "        positronrecovtxz.append(recovtxz[idx])\n",
    "        positrontruevtxz.append(truevtxz[idx])\n",
    "        \n",
    "        positrontestrecovtxz.append(testrecovtxz[idx])\n",
    "        positrontesttruevtxz.append(testtruevtxz[idx])\n",
    "       \n",
    "\n",
    "    idx+=1\n",
    "print('\\nJob complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determining spread for electron old algorithm\n",
    "electronrecovtxz=np.array(electronrecovtxz)\n",
    "electrontruevtxz=np.array(electrontruevtxz)\n",
    "diff_reco_electron=electronrecovtxz-electrontruevtxz\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.displot(diff_reco_electron,color='k')\n",
    "plt.ylim(0, 300)\n",
    "plt.xlim(-200, 200)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "#calculating mean and stuff\n",
    "averagex=np.mean(diff_reco_electron)\n",
    "print(\"The mean is\" , averagex)\n",
    "\n",
    "#Calculating RMS\n",
    "rmsx=np.sqrt(np.mean(diff_reco_electron**2))\n",
    "print(\"The RMS is \" , rmsx)\n",
    "#areaofinterestx=3*rmsx-averagex\n",
    "#print(\"The range of 3 sigma we are counting inside of is \", areaofinterestx)\n",
    "areaofinterestx=200\n",
    "\n",
    "#total number of events\n",
    "totalevents=len(diff_reco_electron)\n",
    "print(\"The total number of events is \" , totalevents)\n",
    "#Counting events within 3 sigma\n",
    "y=0\n",
    "for x in diff_reco_electron:\n",
    "    if x < abs(areaofinterestx):\n",
    "        y=y+1\n",
    "    else:\n",
    "        continue\n",
    "percentcount=y/totalevents\n",
    "print(\"The number events within plus minus 200 is \", y,\"This is\", 100*percentcount, \"% of all events\")\n",
    "print(\"The number of events outside this range is\", totalevents-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data = np.random.normal(loc=5.0, scale=2.0, size=1000)\n",
    "mean,std=norm.fit(diff_reco_electron)\n",
    "\n",
    "plt.hist(diff_reco_electron, bins=1000, normed=True)\n",
    "xmin, xmax = plt.xlim(-200,200)\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "y = norm.pdf(x, mean, std)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "#gauss_fit,cov = curve_fit( Gauss, x, y )\n",
    "print(\"gaussian fit params: The Mean is \", mean)\n",
    "print(\"The STD is \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our model predictions for electron in final state\n",
    "electrontestrecovtxz=np.array(electrontestrecovtxz)\n",
    "electrontesttruevtxz=np.array(electrontesttruevtxz)\n",
    "diff_reco_electron_test=electrontestrecovtxz-electrontesttruevtxz\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.displot(diff_reco_electron_test,color='k')\n",
    "plt.ylim(0, 200)\n",
    "plt.xlim(-200, 200)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "#calculating mean and stuff\n",
    "averagex=np.mean(diff_reco_electron_test)\n",
    "print(\"The mean is\" , averagex)\n",
    "\n",
    "#Calculating RMS\n",
    "rmsx=np.sqrt(np.mean(diff_reco_electron_test**2))\n",
    "print(\"The RMS is \" , rmsx)\n",
    "#areaofinterestx=3*rmsx-averagex\n",
    "#print(\"The range of 3 sigma we are counting inside of is \", areaofinterestx)\n",
    "areaofinterestx=200\n",
    "\n",
    "#total number of events\n",
    "totalevents=len(diff_reco_electron_test)\n",
    "print(\"The total number of events is \" , totalevents)\n",
    "#Counting events within 3 sigma\n",
    "y=0\n",
    "for x in diff_reco_electron_test:\n",
    "    if x < abs(areaofinterestx):\n",
    "        y=y+1\n",
    "    else:\n",
    "        continue\n",
    "percentcount=y/totalevents\n",
    "print(\"The number events within plus minus 200 is \", y,\"This is\", 100*percentcount, \"% of all events\")\n",
    "print(\"The number of events outside this range is\", totalevents-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data = np.random.normal(loc=5.0, scale=2.0, size=1000)\n",
    "mean,std=norm.fit(diff_reco_electron_test)\n",
    "\n",
    "plt.hist(diff_reco_electron_test, bins=1000, normed=True)\n",
    "xmin, xmax = plt.xlim(-50,50)\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "y = norm.pdf(x, mean, std)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "#gauss_fit,cov = curve_fit( Gauss, x, y )\n",
    "print(\"gaussian fit params: The Mean is \", mean)\n",
    "print(\"The STD is \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determining spread for positron old algorithm\n",
    "positronrecovtxz=np.array(positronrecovtxz)\n",
    "positrontruevtxz=np.array(positrontruevtxz)\n",
    "diff_reco_positron=positronrecovtxz-positrontruevtxz\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.displot(diff_reco_positron,color='k')\n",
    "plt.ylim(0, 300)\n",
    "plt.xlim(-300, 500)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "#calculating mean and stuff\n",
    "averagex=np.mean(diff_reco_positron)\n",
    "print(\"The mean is\" , averagex)\n",
    "\n",
    "#Calculating RMS\n",
    "rmsx=np.sqrt(np.mean(diff_reco_positron**2))\n",
    "print(\"The RMS is \" , rmsx)\n",
    "#areaofinterestx=3*rmsx-averagex\n",
    "#print(\"The range of 3 sigma we are counting inside of is \", areaofinterestx)\n",
    "areaofinterestx=50\n",
    "\n",
    "#total number of events\n",
    "totalevents=len(diff_reco_positron)\n",
    "print(\"The total number of events is \" , totalevents)\n",
    "#Counting events within 3 sigma\n",
    "y=0\n",
    "for x in diff_reco_positron:\n",
    "    if x < abs(areaofinterestx):\n",
    "        y=y+1\n",
    "    else:\n",
    "        continue\n",
    "percentcount=y/totalevents\n",
    "print(\"The number events within plus minus 50 is \", y,\"This is\", 100*percentcount, \"% of all events\")\n",
    "print(\"The number of events outside this range is\", totalevents-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data = np.random.normal(loc=5.0, scale=2.0, size=1000)\n",
    "mean,std=norm.fit(diff_reco_positron)\n",
    "\n",
    "plt.hist(diff_reco_positron, bins=1000, normed=True)\n",
    "xmin, xmax = plt.xlim(-200,200)\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "y = norm.pdf(x, mean, std)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "#gauss_fit,cov = curve_fit( Gauss, x, y )\n",
    "print(\"gaussian fit params: The Mean is \", mean)\n",
    "print(\"The STD is \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our model predictions for positron\n",
    "positrontestrecovtxz=np.array(positrontestrecovtxz)\n",
    "positrontesttruevtxz=np.array(positrontesttruevtxz)\n",
    "diff_reco_positron_test=positrontestrecovtxz-positrontesttruevtxz\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.displot(diff_reco_positron_test,color='k')\n",
    "plt.ylim(0, 200)\n",
    "plt.xlim(-100, 100)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "#calculating mean and stuff\n",
    "averagex=np.mean(diff_reco_positron_test)\n",
    "print(\"The mean is\" , averagex)\n",
    "\n",
    "#Calculating RMS\n",
    "rmsx=np.sqrt(np.mean(diff_reco_positron_test**2))\n",
    "print(\"The RMS is \" , rmsx)\n",
    "#areaofinterestx=3*rmsx-averagex\n",
    "#print(\"The range of 3 sigma we are counting inside of is \", areaofinterestx)\n",
    "areaofinterestx=50\n",
    "\n",
    "#total number of events\n",
    "totalevents=len(diff_reco_positron_test)\n",
    "print(\"The total number of events is \" , totalevents)\n",
    "#Counting events within 3 sigma\n",
    "y=0\n",
    "for x in diff_reco_positron_test:\n",
    "    if x < abs(areaofinterestx):\n",
    "        y=y+1\n",
    "    else:\n",
    "        continue\n",
    "percentcount=y/totalevents\n",
    "print(\"The number events within plus minus 50 is \", y,\"This is\", 100*percentcount, \"% of all events\")\n",
    "print(\"The number of events outside this range is\", totalevents-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data = np.random.normal(loc=5.0, scale=2.0, size=1000)\n",
    "mean,std=norm.fit(diff_reco_positron_test)\n",
    "\n",
    "plt.hist(diff_reco_positron_test, bins=1000, normed=True)\n",
    "xmin, xmax = plt.xlim(-50,50)\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "y = norm.pdf(x, mean, std)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "#gauss_fit,cov = curve_fit( Gauss, x, y )\n",
    "print(\"gaussian fit params: The Mean is \", mean)\n",
    "print(\"The STD is \", std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Statistics of Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Ratio: QES = {}, RES = {}, DIS = {}'.format((sum(test_mode==0.0)/len(test_mode)),(sum(test_mode==1.0)/len(test_mode)),(sum(test_mode==2.0)/len(test_mode))))\n",
    "print('Ratio: CC = {}, NC = {}'.format((sum(test_iscc==1.0)/len(test_iscc)),((len(test_iscc)-sum(test_iscc==1.0))/len(test_iscc))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The np array conversions below must be done independently to bypass kernel crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutli dimensional xz & yz views for each event. this is used for plotting events only\n",
    "cvnmap_norm_resh=np.array(cvnmap_norm_resh) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvnmap_norm_resh_xz=np.array(cvnmap_norm_resh_xz) # xz views only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvnmap_norm_resh_yz=np.array(cvnmap_norm_resh_yz) # yz views only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cvnmap_qe_xz=np.array(test_cvnmap_qe_xz)\n",
    "test_cvnmap_qe_yz=np.array(test_cvnmap_qe_yz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cvnmap_res_xz=np.array(test_cvnmap_res_xz)\n",
    "test_cvnmap_res_yz=np.array(test_cvnmap_res_yz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cvnmap_dis_xz=np.array(test_cvnmap_dis_xz)\n",
    "test_cvnmap_dis_yz=np.array(test_cvnmap_dis_yz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cvnmap_cc_xz=np.array(test_cvnmap_cc_xz)\n",
    "test_cvnmap_cc_yz=np.array(test_cvnmap_cc_yz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cvnmap_nc_xz=np.array(test_cvnmap_nc_xz)\n",
    "test_cvnmap_nc_yz=np.array(test_cvnmap_nc_yz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cvnmap_norm_resh_xz=np.array(test_cvnmap_norm_resh_xz) # xz views only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cvnmap_norm_resh_yz=np.array(test_cvnmap_norm_resh_yz) # yz views only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_event_with_vtx(event,idx=0):\n",
    "    pixelmap=event[idx]\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(21, 7))\n",
    "    # added [:-20] to end of pixelmap[X] to preview square images for CNN\n",
    "    sns.heatmap(pixelmap[0][:-20],cmap='coolwarm',cbar=False,square=True,xticklabels=10,yticklabels=10,ax=axes[0])\n",
    "    sns.heatmap(pixelmap[1][:-20],cmap='coolwarm',cbar=False,square=True,xticklabels=10,yticklabels=10,ax=axes[1])\n",
    "#    axes[0].scatter(x=vtxx,y=vtxz,c='yellow',marker='x',s=50)       # comment/uncomment to plot/unplot vertex point\n",
    "#    axes[1].scatter(x=vtxy,y=vtxz,c='yellow',marker='x',s=50)       # comment/uncomment to plot/unplot vertex point\n",
    "    plt.suptitle(\"XZ & YZ Plot\", fontsize=30)\n",
    "    print('UX Specified Fields\\nEvent Number:\\t{}'.format(idx))\n",
    "#    print('CVN Vertex Position (x,y,z) = ({},{},{})'.format(f'{vtxx:.3}',f'{vtxy:.3}',f'{vtxz:.3}'))\n",
    "    axes[0].set_xlabel(\"Cell\", fontsize=25)\n",
    "    axes[0].set_ylabel(\"Plane\", fontsize=25)\n",
    "    axes[1].set_xlabel(\"Cell\", fontsize=25)\n",
    "    axes[1].set_ylabel(\"Plane\", fontsize=25)\n",
    "#    plt.savefig('event.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# verify events plot normally with callable function\n",
    "plot_event_with_vtx(cvnmap_norm_resh,idx=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if GPU is recognized\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None))\n",
    "print(sess)\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    +-----------------------------------------------------------------------------+\n",
    "    | NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\n",
    "    |-------------------------------+----------------------+----------------------+\n",
    "    | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "    | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "    |===============================+======================+======================|\n",
    "    |   0  Tesla V100-PCIE...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
    "    | N/A   33C    P0    34W / 250W |  15431MiB / 16160MiB |      0%      Default |\n",
    "    +-------------------------------+----------------------+----------------------+\n",
    "    |   1  Tesla V100-PCIE...  Off  | 00000000:D8:00.0 Off |                    0 |\n",
    "    | N/A   34C    P0    34W / 250W |      0MiB / 16160MiB |      5%      Default |\n",
    "    +-------------------------------+----------------------+----------------------+\n",
    "                                                                                   \n",
    "    +-----------------------------------------------------------------------------+\n",
    "    | Processes:                                                       GPU Memory |\n",
    "    |  GPU       PID   Type   Process name                             Usage      |\n",
    "    |=============================================================================|\n",
    "    |    0    152871      C   python3                                    15419MiB |\n",
    "    +-----------------------------------------------------------------------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the Training & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XZ view. Trains on the x-coordinate\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(cvnmap_norm_resh_xz, truevtxz, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YZ view. Trains on the y-cooridnate\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(cvnmap_norm_resh_yz, truevtxz, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add one more dimension to let the CNN know we are dealing with one color dimension\n",
    "x1_train=X1_train.reshape(X1_train.shape[0],100,80,1)\n",
    "x1_test=X1_test.reshape(X1_test.shape[0],100,80,1)\n",
    "x2_train=X2_train.reshape(X2_train.shape[0],100,80,1)\n",
    "x2_test=X2_test.reshape(X2_test.shape[0],100,80,1)\n",
    "#batch_size,width,heigh,color_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add one more dimension to let the CNN know we are dealing with one color dimension\n",
    "test_cvnmap_qe_xz=test_cvnmap_qe_xz.reshape(test_cvnmap_qe_xz.shape[0],100,80,1)\n",
    "test_cvnmap_qe_yz=test_cvnmap_qe_yz.reshape(test_cvnmap_qe_yz.shape[0],100,80,1)\n",
    "test_cvnmap_res_xz=test_cvnmap_res_xz.reshape(test_cvnmap_res_xz.shape[0],100,80,1)\n",
    "test_cvnmap_res_yz=test_cvnmap_res_yz.reshape(test_cvnmap_res_yz.shape[0],100,80,1)\n",
    "test_cvnmap_dis_xz=test_cvnmap_dis_xz.reshape(test_cvnmap_dis_xz.shape[0],100,80,1)\n",
    "test_cvnmap_dis_yz=test_cvnmap_dis_yz.reshape(test_cvnmap_dis_yz.shape[0],100,80,1)\n",
    "#batch_size,width,heigh,color_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add one more dimension to let the CNN know we are dealing with one color dimension\n",
    "test_cvnmap_cc_xz=test_cvnmap_cc_xz.reshape(test_cvnmap_cc_xz.shape[0],100,80,1)\n",
    "test_cvnmap_cc_yz=test_cvnmap_cc_yz.reshape(test_cvnmap_cc_yz.shape[0],100,80,1)\n",
    "test_cvnmap_nc_xz=test_cvnmap_nc_xz.reshape(test_cvnmap_nc_xz.shape[0],100,80,1)\n",
    "test_cvnmap_nc_yz=test_cvnmap_nc_yz.reshape(test_cvnmap_nc_yz.shape[0],100,80,1)\n",
    "#batch_size,width,heigh,color_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom regression loss functions\n",
    "# huber loss\n",
    "def huber(true, pred, delta):\n",
    "    loss = np.where(np.abs(true-pred) < delta , 0.5*((true-pred)**2), delta*np.abs(true - pred) - 0.5*(delta**2))\n",
    "    return np.sum(loss)\n",
    "\n",
    "# log cosh loss\n",
    "def logcosh(true, pred):\n",
    "    loss = np.log(np.cosh(pred - true))\n",
    "    return np.sum(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiView Fully Connected Layer Regression CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instantiate the models\n",
    "model_regCNN_xz = Sequential()\n",
    "model_regCNN_yz = Sequential()\n",
    "# add two fully connected 2-dimensional convolutional layers for the XZ and YZ views\n",
    "model_regCNN_xz.add(Conv2D(filters=32,kernel_size=(2,2),strides=(1,1),\n",
    "                  input_shape=(100,80,1),activation='relu'))\n",
    "model_regCNN_yz.add(Conv2D(filters=32,kernel_size=(2,2),strides=(1,1),\n",
    "                 input_shape=(100,80,1),activation='relu'))\n",
    "# specify 2-dimensional pooling\n",
    "model_regCNN_xz.add(MaxPool2D(pool_size=(2,2)))\n",
    "model_regCNN_yz.add(MaxPool2D(pool_size=(2,2)))\n",
    "# flatten the datasets\n",
    "model_regCNN_xz.add(Flatten())\n",
    "model_regCNN_yz.add(Flatten())\n",
    "# add dense layers for each view. 256 neurons per layer\n",
    "model_regCNN_xz.add(Dense(256,activation='relu'))\n",
    "model_regCNN_yz.add(Dense(256,activation='relu'))\n",
    "model_regCNN_xz.add(Dense(256,activation='relu'))\n",
    "model_regCNN_yz.add(Dense(256,activation='relu'))\n",
    "model_regCNN_xz.add(Dense(256,activation='relu'))\n",
    "model_regCNN_yz.add(Dense(256,activation='relu'))\n",
    "model_regCNN_xz.add(Dense(256,activation='relu'))\n",
    "model_regCNN_yz.add(Dense(256,activation='relu'))\n",
    "model_regCNN_xz.add(Dense(256,activation='relu'))\n",
    "model_regCNN_yz.add(Dense(256,activation='relu'))\n",
    "model_regCNN_xz.add(Dense(256,activation='relu'))\n",
    "model_regCNN_yz.add(Dense(256,activation='relu'))\n",
    "# no. of classes (output)\n",
    "n_classes=1\n",
    "# tf concatenate the models\n",
    "model_regCNN_concat = concatenate([model_regCNN_xz.output, model_regCNN_yz.output],axis=-1)\n",
    "model_regCNN_concat = Dense(n_classes)(model_regCNN_concat)\n",
    "model_regCNN = Model(inputs=[model_regCNN_xz.input, model_regCNN_yz.input], outputs=model_regCNN_concat)\n",
    "# compile the concatenated model\n",
    "model_regCNN.compile(loss='logcosh', optimizer='adam') # loss was 'mse' then 'mae'\n",
    "# print a summary of the model\n",
    "print(model_regCNN.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# z-coordinate system\n",
    "model_regCNN.fit(x=[x1_train,x2_train],y=y1_train,epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Mean Square Error (MSE) is the most commonly used regression loss function. MSE is the sum of squared distances between our target variable and predicted values.\n",
    "    Mean Absolute Error (MAE) is the sum of absolute differences between our target and predicted variables.MAE loss is useful if the training data is corrupted with outliers (i.e. we erroneously receive unrealistically huge negative/positive values in our training environment, but not our testing environment). One big problem in using MAE loss (for neural nets especially) is that its gradient is the same throughout, which means the gradient will be large even for small loss values. This isn’t good for learning. To fix this, we can use dynamic learning rate which decreases as we move closer to the minima.\n",
    "    Huber loss is less sensitive to outliers in data than the squared error loss. It’s also differentiable at 0. It’s basically absolute error, which becomes quadratic when error is small. How small that error has to be to make it quadratic depends on a hyperparameter, 𝛿 (delta), which can be tuned. Huber loss approaches MSE when 𝛿 ~ 0 and MAE when 𝛿 ~ ∞ (large numbers.)\n",
    "    Log-cosh is the logarithm of the hyperbolic cosine of the prediction error. log(cosh(x)) is approximately equal to (x ** 2) / 2 for small x and to abs(x) - log(2) for large x. This means that 'logcosh' works mostly like the mean squared error, but will not be so strongly affected by the occasional wildly incorrect prediction. It has all the advantages of Huber loss, and it’s twice differentiable everywhere, unlike Huber loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation with logcosh 200 epoch\n",
    "metrics = pd.DataFrame(model_regCNN.history.history)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(metrics[['loss']])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "#plt.savefig('x-train-loss.pdf')\n",
    "plt.savefig('z-train-loss_2.png',dpi=600)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_predictions=model_regCNN.predict([test_cvnmap_qe_xz,test_cvnmap_qe_yz])\n",
    "res_predictions=model_regCNN.predict([test_cvnmap_res_xz,test_cvnmap_res_yz])\n",
    "dis_predictions=model_regCNN.predict([test_cvnmap_dis_xz,test_cvnmap_dis_yz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_predictions=model_regCNN.predict([test_cvnmap_cc_xz,test_cvnmap_cc_yz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_predictions=model_regCNN.predict([test_cvnmap_nc_xz,test_cvnmap_nc_yz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall\n",
    "full_pred_df=pd.DataFrame(testtruevtxz,columns=['Test True Z'])\n",
    "full_test_predictions=pd.Series(full_predictions.reshape(testtruevtxz.shape[0],))\n",
    "full_pred_df=pd.concat([full_pred_df,full_predictions,axis=1])\n",
    "full_pred_df.columns=['Test True Z','Model Predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test before sending to csv\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.xlabel('True Z Vertex (cm)')\n",
    "plt.ylabel('Model Z Vertex (cm)')\n",
    "sns.kdeplot(data=nc_pred_df,x='Test True Z',y='Test Reco Z',fill=True)\n",
    "plt.ylim(0, 1600)\n",
    "plt.xlim(0, 1600)\n",
    "plt.plot(y1_test,y1_test,'r',lw=0.5,ls='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test before sending to csv\n",
    "x_diff=full_test_predictions-testtruevtxx\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.displot(x_diff,color='k')\n",
    "plt.ylim(0, 3500)\n",
    "plt.xlim(-300, 300)\n",
    "plt.xlabel('Model Prediction - True (cm)')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test before sending to csv\n",
    "diff_reco=truevtxz-recovtxz\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.displot(diff_reco,color='k')\n",
    "plt.ylim(0, 3500)\n",
    "plt.xlim(-300, 300)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "#calculating mean and stuff\n",
    "\n",
    "for n,i in enumerate(diff_reco):\n",
    "    if i < -300:\n",
    "        diff_reco[n]=0\n",
    "   \n",
    "\n",
    "averagez=np.mean(diff_reco)\n",
    "print(\"The mean is\" , averagez)\n",
    "\n",
    "#Calculating RMS\n",
    "rmsz=np.sqrt(np.mean(diff_reco**2))\n",
    "print(\"The RMS is \" , rmsz)\n",
    "#areaofinterestz=3*rmsz-averagez\n",
    "#print(\"The range of 3 sigma we are counting inside of is \", areaofinterestz)\n",
    "areaofinterestx=200\n",
    "\n",
    "#total number of events\n",
    "totalevents=len(diff_reco)\n",
    "print(\"The total number of events is \" , totalevents)\n",
    "#Counting events within 3 sigma\n",
    "y=0\n",
    "for x in diff_reco:\n",
    "    if x < abs(areaofinterestx):\n",
    "        y=y+1\n",
    "    else:\n",
    "        continue\n",
    "percentcount=y/totalevents\n",
    "print(\"The number events within plus minus 200 is \", y,\"This is\", 100*percentcount, \"% of all events\")\n",
    "print(\"The number of events outside this range is\", totalevents-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data = np.random.normal(loc=5.0, scale=2.0, size=1000)\n",
    "mean,std=norm.fit(diff_reco)\n",
    "\n",
    "plt.hist(diff_reco, bins=1000, normed=True)\n",
    "xmin, xmax = plt.xlim(-200,200)\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "y = norm.pdf(x, mean, std)\n",
    "\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "#plt.xlim(-2000,2000)\n",
    "plt.xlim(-200,200)\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "#gauss_fit,cov = curve_fit( Gauss, x, y )\n",
    "print(\"gaussian fit params: The Mean is \", mean)\n",
    "print(\"The STD is \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True-Reco for the new reconstruction method (model predictions)\n",
    "\n",
    "\n",
    "# test before sending to csv\n",
    "diff_reco_new=testtruevtxz-testrecovtxz\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.displot(diff_reco_new,color='k')\n",
    "#sns.displot(diff_reco)\n",
    "#plt.plot(x_values, y_values.pdf(x_values))\n",
    "plt.ylim(0, 3500)\n",
    "plt.xlim(-300, 300)\n",
    "#plt.ylim(0, 250)\n",
    "#plt.xlim(-100, 100)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "\n",
    "#calculating mean and stuff\n",
    "averagez=np.mean(diff_reco_new)\n",
    "print(\"The mean is\" , averagez)\n",
    "\n",
    "#Calculating RMS\n",
    "rmsz=np.sqrt(np.mean(diff_reco_new**2))\n",
    "print(\"The RMS is \" , rmsz)\n",
    "#areaofinterestz=3*rmsz-averagez\n",
    "#print(\"The range of 3 sigma we are counting inside of is \", areaofinterestz)\n",
    "areaofinterestx=200\n",
    "\n",
    "#total number of events\n",
    "totalevents=len(diff_reco_new)\n",
    "print(\"The total number of events is \" , totalevents)\n",
    "#Counting events within 3 sigma\n",
    "y=0\n",
    "for x in diff_reco_new:\n",
    "    if x < abs(areaofinterestx):\n",
    "        y=y+1\n",
    "    else:\n",
    "        continue\n",
    "percentcount=y/totalevents\n",
    "print(\"The number events within plus minus 200 is \", y,\"This is\", 100*percentcount, \"% of all events\")\n",
    "print(\"The number of events outside this range is\", totalevents-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data = np.random.normal(loc=5.0, scale=2.0, size=1000)\n",
    "mean,std=norm.fit(diff_reco_new)\n",
    "\n",
    "plt.hist(diff_reco_new, bins=5000, normed=True)\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "y = norm.pdf(x, mean, std)\n",
    "plt.xlabel('Reco - True (cm)')\n",
    "plt.ylabel('Count')\n",
    "#plt.xlim(-1000,1000)\n",
    "plt.xlim(-200,200)\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "#gauss_fit,cov = curve_fit( Gauss, x, y )\n",
    "print(\"gaussian fit params: The Mean is \", mean)\n",
    "print(\"The STD is \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "h = numpy.histogram(diff_reco)\n",
    "sns.displot(diff_reco)\n",
    "sns.displot(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energyspread = numpy.histogram(energy)\n",
    "sns.displot(energy)\n",
    "sns.displot(energyspread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model Predictions, True Data, and Reco Data for Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qe interactions\n",
    "qe_pred_df=pd.DataFrame(qe_true_vtxz,columns=['Test True Z'])\n",
    "qe_reco_df=pd.DataFrame(qe_reco_vtxz,columns=['Test Reco Z'])\n",
    "qe_predictions=pd.Series(qe_predictions.reshape(len(qe_true_vtxz),))\n",
    "qe_pred_df=pd.concat([qe_pred_df,qe_predictions],axis=1)\n",
    "qe_pred_df=pd.concat([qe_pred_df,qe_reco_df],axis=1)\n",
    "qe_pred_df.columns=['Test True Z','Model Predictions','Test Reco Z']\n",
    "np.savetxt(\"z_model_predictions_qe.csv\", qe_pred_df, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res interactions\n",
    "res_pred_df=pd.DataFrame(res_true_vtxz,columns=['Test True Z'])\n",
    "res_reco_df=pd.DataFrame(res_reco_vtxz,columns=['Test Reco Z'])\n",
    "res_predictions=pd.Series(res_predictions.reshape(len(res_true_vtxz),))\n",
    "res_pred_df=pd.concat([res_pred_df,res_predictions],axis=1)\n",
    "res_pred_df=pd.concat([res_pred_df,res_reco_df],axis=1)\n",
    "res_pred_df.columns=['Test True Z','Model Predictions','Test Reco Z']\n",
    "np.savetxt(\"z_model_predictions_res.csv\", res_pred_df, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dis interactions\n",
    "dis_pred_df=pd.DataFrame(dis_true_vtxz,columns=['Test True Z'])\n",
    "dis_reco_df=pd.DataFrame(dis_reco_vtxz,columns=['Test Reco Z'])\n",
    "dis_predictions=pd.Series(dis_predictions.reshape(len(dis_true_vtxz),))\n",
    "dis_pred_df=pd.concat([dis_pred_df,dis_predictions],axis=1)\n",
    "dis_pred_df=pd.concat([dis_pred_df,dis_reco_df],axis=1)\n",
    "dis_pred_df.columns=['Test True Z','Model Predictions','Test Reco Z']\n",
    "np.savetxt(\"z_model_predictions_dis.csv\", dis_pred_df, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc interactions\n",
    "cc_pred_df=pd.DataFrame(cc_true_vtxz,columns=['Test True Z'])\n",
    "cc_reco_df=pd.DataFrame(cc_reco_vtxz,columns=['Test Reco Z'])\n",
    "cc_predictions=pd.Series(cc_predictions.reshape(len(cc_true_vtxz),))\n",
    "cc_pred_df=pd.concat([cc_pred_df,cc_predictions],axis=1)\n",
    "cc_pred_df=pd.concat([cc_pred_df,cc_reco_df],axis=1)\n",
    "cc_pred_df.columns=['Test True Z','Model Predictions','Test Reco Z']\n",
    "np.savetxt(\"z_model_predictions_cc.csv\", cc_pred_df, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nc interactions\n",
    "nc_pred_df=pd.DataFrame(nc_true_vtxz,columns=['Test True Z'])\n",
    "nc_reco_df=pd.DataFrame(nc_reco_vtxz,columns=['Test Reco Z'])\n",
    "nc_predictions=pd.Series(nc_predictions.reshape(len(nc_true_vtxz),))\n",
    "nc_pred_df=pd.concat([nc_pred_df,nc_predictions],axis=1)\n",
    "nc_pred_df=pd.concat([nc_pred_df,nc_reco_df],axis=1)\n",
    "nc_pred_df.columns=['Test True Z','Model Predictions','Test Reco Z']\n",
    "np.savetxt(\"z_model_predictions_nc.csv\", nc_pred_df, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_reco_true_vtxz=pd.DataFrame(qe_reco_true_vtxz)\n",
    "qe_reco_vtxz=pd.DataFrame(qe_reco_vtxz)\n",
    "res_reco_true_vtxz=pd.DataFrame(res_reco_true_vtxz)\n",
    "res_reco_vtxz=pd.DataFrame(res_reco_vtxz)\n",
    "dis_reco_true_vtxz=pd.DataFrame(dis_reco_true_vtxz)\n",
    "dis_reco_vtxz=pd.DataFrame(dis_reco_vtxz)\n",
    "cc_reco_true_vtxz=pd.DataFrame(cc_reco_true_vtxz)\n",
    "cc_reco_vtxz=pd.DataFrame(cc_reco_vtxz)\n",
    "nc_reco_true_vtxz=pd.DataFrame(nc_reco_true_vtxz)\n",
    "nc_reco_vtxz=pd.DataFrame(nc_reco_vtxz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qe_reco_vtxz=[]\n",
    "#dis_reco_vtxz=[]\n",
    "#res_reco_vtxz=[]\n",
    "#cc_reco_vtxz=[]\n",
    "#nc_reco_vtxz=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_reco_vtxz=pd.concat([qe_reco_vtxz,qe_reco_true_vtxz],axis=1)\n",
    "dis_reco_vtxz=pd.concat([dis_reco_vtxz,dis_reco_true_vtxz],axis=1)\n",
    "res_reco_vtxz=pd.concat([res_reco_vtxz,res_reco_true_vtxz],axis=1)\n",
    "cc_reco_vtxz=pd.concat([cc_reco_vtxz,cc_reco_true_vtxz],axis=1)\n",
    "nc_reco_vtxz=pd.concat([nc_reco_vtxz,nc_reco_true_vtxz],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"z_reco_qe.csv\", qe_reco_vtxz, delimiter=\",\")\n",
    "np.savetxt(\"z_reco_res.csv\", dis_reco_vtxz, delimiter=\",\")\n",
    "np.savetxt(\"z_reco_dis.csv\", res_reco_vtxz, delimiter=\",\")\n",
    "np.savetxt(\"z_reco_cc.csv\", cc_reco_vtxz, delimiter=\",\")\n",
    "np.savetxt(\"z_reco_nc.csv\", nc_reco_vtxz, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
